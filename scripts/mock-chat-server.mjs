import http from 'node:http'
import { randomUUID } from 'node:crypto'
import { URL } from 'node:url'

const HOST = process.env.MOCK_API_HOST || '127.0.0.1'
const PORT = Number(process.env.MOCK_API_PORT || 8787)
const DEFAULT_MODEL = process.env.MOCK_API_MODEL || 'mock-gemini-2.5-flash'
const EMPTY_TOOL_CALL_RATE = Math.max(0, Math.min(1, Number(process.env.MOCK_EMPTY_TOOL_CALL_RATE || 0)))

function nowSeconds() {
  return Math.floor(Date.now() / 1000)
}

function toText(content) {
  if (typeof content === 'string') return content
  if (!Array.isArray(content)) return ''
  return content
    .map((item) => {
      if (typeof item === 'string') return item
      if (!item || typeof item !== 'object') return ''
      if (typeof item.text === 'string') return item.text
      if (typeof item.type === 'string' && item.type === 'text' && typeof item.text === 'string') return item.text
      return ''
    })
    .filter(Boolean)
    .join('\n')
}

function getMessages(body) {
  return Array.isArray(body?.messages) ? body.messages : []
}

function latestTextByRole(messages, role) {
  for (let i = messages.length - 1; i >= 0; i -= 1) {
    if (messages[i]?.role === role) return toText(messages[i]?.content)
  }
  return ''
}

function createChatCompletion({ model, message, finishReason = 'stop' }) {
  return {
    id: `req_${Date.now()}_${randomUUID().slice(0, 8)}`,
    object: 'chat.completion',
    created: nowSeconds(),
    model: model || DEFAULT_MODEL,
    choices: [
      {
        index: 0,
        message,
        finish_reason: finishReason,
      },
    ],
    usage: {
      prompt_tokens: 0,
      completion_tokens: 0,
      total_tokens: 0,
    },
  }
}

function hasVisionInput(messages) {
  return messages.some((msg) => {
    if (!Array.isArray(msg?.content)) return false
    return msg.content.some((item) => item?.type === 'image_url')
  })
}

function makeWorkflowPlan(latestUserText) {
  return {
    workflow_id: `wf_mock_${Date.now()}`,
    tasks: [
      {
        task_id: 'task_full_toolchain',
        model_type: 'tool',
        input_prompt:
          'Run the full toolchain in one round by calling every provided tool exactly once with safe mock arguments, then summarize.',
        dependencies: [],
        use_tools: true,
      },
    ],
    final_intent: `Summarize full mock toolchain execution for the user request: ${latestUserText || 'none'}`,
  }
}

function buildDefaultToolArgs(name) {
  if (name === 'file_read') return { path: 'test/2.txt' }
  if (name === 'file_write') {
    return {
      path: 'test/generated_view.html',
      content:
        '<!doctype html><html><head><meta charset="utf-8"><title>Mock</title></head><body><h1>Mock Full Toolchain</h1><p>Generated by local mock backend.</p></body></html>',
    }
  }
  if (name === 'file_list') return { path: '.', recursive: false }
  if (name === 'file_info') return { path: 'test/2.txt' }
  if (name === 'open_in_browser') return { path: 'test/generated_view.html' }
  if (name === 'live2d_control') return { action_type: 'expression', action_name: '马尾R隐藏' }
  if (name === 'vision_analyze') return { image_path: 'test/sample.png', prompt: 'mock vision check' }
  if (name === 'web_search') return { query: 'mock backend test' }
  if (name === 'memory_search') return { query: 'mock memory query', topK: 5 }
  if (name === 'conversation_search') return { query: 'mock conversation query', limit: 10 }
  return {}
}

function makeToolCallResponse(body) {
  const tools = Array.isArray(body?.tools) ? body.tools : []
  const uniqueToolNames = Array.from(new Set(tools.map((item) => item?.function?.name).filter(Boolean)))

  if (EMPTY_TOOL_CALL_RATE > 0 && Math.random() < EMPTY_TOOL_CALL_RATE) {
    return createChatCompletion({
      model: body?.model,
      message: { role: 'assistant', content: '' },
      finishReason: null,
    })
  }

  if (uniqueToolNames.length === 0) {
    return createChatCompletion({
      model: body?.model,
      message: { role: 'assistant', content: 'No tools available in request.' },
      finishReason: 'stop',
    })
  }

  const toolCalls = uniqueToolNames.map((name) => ({
    id: `call_${randomUUID().slice(0, 10)}`,
    type: 'function',
    function: {
      name,
      arguments: JSON.stringify(buildDefaultToolArgs(name)),
    },
  }))

  return createChatCompletion({
    model: body?.model,
    message: {
      role: 'assistant',
      content: '',
      tool_calls: toolCalls,
    },
    finishReason: 'tool_calls',
  })
}

function makeNoToolResponse(body, messages) {
  const latestUserText = latestTextByRole(messages, 'user')
  const systemText = messages
    .filter((item) => item?.role === 'system')
    .map((item) => toText(item?.content))
    .join('\n')

  if (/orchestrator model for a dependency-based workflow system/i.test(systemText)) {
    const plan = makeWorkflowPlan(latestUserText)
    return createChatCompletion({
      model: body?.model,
      message: { role: 'assistant', content: JSON.stringify(plan, null, 2) },
      finishReason: 'stop',
    })
  }

  if (/orchestrator final synthesis stage/i.test(systemText)) {
    return createChatCompletion({
      model: body?.model,
      message: { role: 'assistant', content: 'Mock final synthesis: full toolchain simulation completed.' },
      finishReason: 'stop',
    })
  }

  if (/You are the Coder worker/i.test(systemText)) {
    const content =
      '```html\n<!doctype html>\n<html>\n  <head>\n    <meta charset="utf-8" />\n    <title>Mock Generated</title>\n  </head>\n  <body>\n    <h1>Hello!</h1>\n    <p>This HTML is generated by local mock backend.</p>\n  </body>\n</html>\n```'
    return createChatCompletion({
      model: body?.model,
      message: { role: 'assistant', content },
      finishReason: 'stop',
    })
  }

  if (hasVisionInput(messages)) {
    return createChatCompletion({
      model: body?.model,
      message: {
        role: 'assistant',
        content: 'Mock vision result: image received and analyzed locally in mock mode.',
      },
      finishReason: 'stop',
    })
  }

  return createChatCompletion({
    model: body?.model,
    message: { role: 'assistant', content: `Mock response: ${latestUserText || 'ok'}` },
    finishReason: 'stop',
  })
}

function readBody(req) {
  return new Promise((resolve, reject) => {
    const chunks = []
    req.on('data', (chunk) => chunks.push(chunk))
    req.on('end', () => {
      try {
        const raw = Buffer.concat(chunks).toString('utf8')
        resolve(raw ? JSON.parse(raw) : {})
      } catch (error) {
        reject(error)
      }
    })
    req.on('error', reject)
  })
}

function sendJson(res, statusCode, payload) {
  res.statusCode = statusCode
  res.setHeader('Content-Type', 'application/json; charset=utf-8')
  res.end(JSON.stringify(payload))
}

function isChatCompletionPath(pathname) {
  return /\/chat\/completions$/i.test(pathname.replace(/\/+$/, ''))
}

const server = http.createServer(async (req, res) => {
  const url = new URL(req.url || '/', `http://${req.headers.host || 'localhost'}`)
  const pathname = url.pathname

  if (req.method === 'GET' && pathname === '/health') {
    return sendJson(res, 200, { ok: true, mode: 'mock', model: DEFAULT_MODEL })
  }

  if (req.method === 'GET' && (pathname === '/v1/models' || pathname === '/models')) {
    return sendJson(res, 200, {
      object: 'list',
      data: [
        { id: DEFAULT_MODEL, object: 'model', created: nowSeconds(), owned_by: 'mock' },
        { id: 'mock-gemini-3-pro-preview-low', object: 'model', created: nowSeconds(), owned_by: 'mock' },
      ],
    })
  }

  if (req.method === 'POST' && isChatCompletionPath(pathname)) {
    try {
      const body = await readBody(req)
      const messages = getMessages(body)
      const hasTools = Array.isArray(body?.tools) && body.tools.length > 0
      const hasToolMessages = messages.some((item) => item?.role === 'tool')

      let payload
      if (hasTools && !hasToolMessages) {
        payload = makeToolCallResponse(body)
      } else if (hasToolMessages) {
        const toolText = messages
          .filter((item) => item?.role === 'tool')
          .map((item) => toText(item?.content))
          .filter(Boolean)
          .join('\n')
        payload = createChatCompletion({
          model: body?.model,
          message: {
            role: 'assistant',
            content: toolText ? `Mock full toolchain handled:\n${toolText}` : 'Mock full toolchain handled.',
          },
          finishReason: 'stop',
        })
      } else {
        payload = makeNoToolResponse(body, messages)
      }

      return sendJson(res, 200, payload)
    } catch (error) {
      return sendJson(res, 400, {
        error: 'invalid_request',
        message: error instanceof Error ? error.message : String(error),
      })
    }
  }

  return sendJson(res, 404, { error: 'not_found', path: pathname })
})

server.listen(PORT, HOST, () => {
  console.log(`[mock-api] listening on http://${HOST}:${PORT}`)
  console.log(`[mock-api] chat endpoint: http://${HOST}:${PORT}/v1/chat/completions`)
  console.log(`[mock-api] mode: full-toolchain on every trigger`)
  console.log(`[mock-api] env: MOCK_EMPTY_TOOL_CALL_RATE=${EMPTY_TOOL_CALL_RATE}`)
})
